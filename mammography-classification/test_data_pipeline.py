import yaml
import sys
from pathlib import Path

#add src to path
SCRIPT_DIR = Path(__file__).parent
sys.path.append(str(SCRIPT_DIR))

from src.data.preprocessing import get_transforms
from src.data.dataset import create_dataloaders

#load config
config_path = SCRIPT_DIR / "configs" / "config.yaml"
with open(config_path, "r") as f:
    cfg = yaml.safe_load(f)

if __name__ == '__main__':
    print("="*50)
    print("ğŸ§ª Testing Data Pipeline...")
    print("="*50)

    #get transforms
    print("\nğŸ“‹ Getting transforms...")
    transforms = get_transforms(cfg) 
    print("âœ… Transforms created successfully.")

    #create dataloaders
    print("\nğŸ“‹ Creating dataloaders...")
    loaders, sizes, class_names = create_dataloaders(cfg, transforms)

    print("\nğŸ“Š Dataset Summary: ")
    print(f"   Classes: {class_names}")
    print(f"   Number of classes: {len(class_names)}")
    for split, size in sizes.items():
        print(f"   {split.capitalize()}: {size} images")

    #test loading a batch
    print("\nğŸ” Testing batch loading from train set...")
    train_loader = loaders['train']
    images, labels = next(iter(train_loader))
    print(f"âœ… Batch loaded successfully!")
    print(f"   Batch shape: {images.shape}")
    print(f"   Labels shape: {labels.shape}")
    print(f"   Labels in batch: {labels.tolist()}")
    print(f"   Image dtype: {images.dtype}")
    print(f"   Image min/max: {images.min().item():.4f}/{images.max().item():.4f}")

    print("\n" + "="*50)
    print("âœ… Data Pipeline Test PASSED!")
    print("="*50)
print("="*50)    